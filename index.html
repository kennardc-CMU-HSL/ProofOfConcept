<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video Demos</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

  <header>
    <h1>Video Demos</h1>
    <p>See our initial results (1 Month of Progress). Our ultimate aim is to move towards multi-agent world models, but below represents our first steps. Synthetic videos are easily manipulatable in both the video content and the camera movement. However, synthetic videos, by its nature, are not photorealistic. To generate training data of a photorealistic multi-agent environment, we need to find a way to convert synthetic videos into photorealistic ones. </p>
  </header>

  <main>
    <div class="container">
      
      <h2 class="section-title">Early Progress achieved in converting Synthetic Videos into 'Real' Videos</h2>
      <div id="comparison-gallery" class="gallery-grid">
        </div>

      <hr class="section-divider">

      <h2 class="section-title">Our Target/Aim: Videos of different Camera Trajectories that adhere to the same timeline</h2>
      <div id="trajectory-gallery" class="gallery-grid">
        </div>

    </div>
  </main>

  <footer>
    <p>Â© 2026 CMU Human Sensing Lab</p>
  </footer>

  <script src="script.js"></script>
</body>
</html>
